Logging to Checkpoints/Checkpoint_TwoChan_Exp_2
creating model and diffusion...
creating data loader...
training...
loading model from checkpoint: Checkpoints/Checkpoint_TwoChan_Exp_2/model110000.pt...
loading optimizer state from checkpoint: Checkpoints/Checkpoint_TwoChan_Exp_2/opt110000.pt
loading EMA from checkpoint: Checkpoints/Checkpoint_TwoChan_Exp_2/ema_0.9999_110000.pt...
------------------------
| grad_norm | 0.0681   |
| loss      | 0.00227  |
| loss_q0   | 0.00703  |
| loss_q1   | 0.000916 |
| loss_q2   | 0.000319 |
| loss_q3   | 0.000119 |
| mse       | 0.00223  |
| mse_q0    | 0.00693  |
| mse_q1    | 0.000909 |
| mse_q2    | 0.000316 |
| mse_q3    | 0.000118 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 3.03e-05 |
| vb_q0     | 9.84e-05 |
| vb_q1     | 6.78e-06 |
| vb_q2     | 2.55e-06 |
| vb_q3     | 1.57e-06 |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.0661   |
| loss      | 0.00151  |
| loss_q0   | 0.00604  |
| loss_q1   | 0.000974 |
| loss_q2   | 0.000212 |
| loss_q3   | 0.000109 |
| mse       | 0.00149  |
| mse_q0    | 0.00593  |
| mse_q1    | 0.000967 |
| mse_q2    | 0.00021  |
| mse_q3    | 0.000108 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 2.45e-05 |
| vb_q0     | 0.00011  |
| vb_q1     | 7.28e-06 |
| vb_q2     | 2e-06    |
| vb_q3     | 1.35e-06 |
------------------------
------------------------
| grad_norm | 0.0749   |
| loss      | 0.00175  |
| loss_q0   | 0.00823  |
| loss_q1   | 0.00112  |
| loss_q2   | 0.00022  |
| loss_q3   | 0.0001   |
| mse       | 0.00172  |
| mse_q0    | 0.00801  |
| mse_q1    | 0.00111  |
| mse_q2    | 0.000218 |
| mse_q3    | 9.91e-05 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 3.72e-05 |
| vb_q0     | 0.000214 |
| vb_q1     | 8.34e-06 |
| vb_q2     | 2e-06    |
| vb_q3     | 1.29e-06 |
------------------------
------------------------
| grad_norm | 0.108    |
| loss      | 0.00193  |
| loss_q0   | 0.00933  |
| loss_q1   | 0.000939 |
| loss_q2   | 0.000277 |
| loss_q3   | 9.73e-05 |
| mse       | 0.00188  |
| mse_q0    | 0.00905  |
| mse_q1    | 0.000932 |
| mse_q2    | 0.000275 |
| mse_q3    | 9.6e-05  |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 5e-05    |
| vb_q0     | 0.000276 |
| vb_q1     | 6.9e-06  |
| vb_q2     | 2.41e-06 |
| vb_q3     | 1.24e-06 |
------------------------
------------------------
| grad_norm | 0.0796   |
| loss      | 0.00218  |
| loss_q0   | 0.00862  |
| loss_q1   | 0.00115  |
| loss_q2   | 0.000289 |
| loss_q3   | 9.74e-05 |
| mse       | 0.00212  |
| mse_q0    | 0.00834  |
| mse_q1    | 0.00114  |
| mse_q2    | 0.000286 |
| mse_q3    | 9.61e-05 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 6e-05    |
| vb_q0     | 0.000282 |
| vb_q1     | 8.56e-06 |
| vb_q2     | 2.64e-06 |
| vb_q3     | 1.26e-06 |
------------------------
------------------------
| grad_norm | 0.145    |
| loss      | 0.00501  |
| loss_q0   | 0.0164   |
| loss_q1   | 0.000869 |
| loss_q2   | 0.000212 |
| loss_q3   | 0.000101 |
| mse       | 0.00423  |
| mse_q0    | 0.0137   |
| mse_q1    | 0.000862 |
| mse_q2    | 0.00021  |
| mse_q3    | 9.94e-05 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 0.000784 |
| vb_q0     | 0.00273  |
| vb_q1     | 6.4e-06  |
| vb_q2     | 1.92e-06 |
| vb_q3     | 1.21e-06 |
------------------------
------------------------
| grad_norm | 0.111    |
| loss      | 0.00233  |
| loss_q0   | 0.00571  |
| loss_q1   | 0.000973 |
| loss_q2   | 0.000266 |
| loss_q3   | 0.000105 |
| mse       | 0.00228  |
| mse_q0    | 0.00557  |
| mse_q1    | 0.000966 |
| mse_q2    | 0.000264 |
| mse_q3    | 0.000104 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 5.47e-05 |
| vb_q0     | 0.000142 |
| vb_q1     | 7.21e-06 |
| vb_q2     | 2.36e-06 |
| vb_q3     | 1.3e-06  |
------------------------
------------------------
| grad_norm | 0.109    |
| loss      | 0.00254  |
| loss_q0   | 0.00912  |
| loss_q1   | 0.00115  |
| loss_q2   | 0.000257 |
| loss_q3   | 9.26e-05 |
| mse       | 0.00244  |
| mse_q0    | 0.00869  |
| mse_q1    | 0.00114  |
| mse_q2    | 0.000255 |
| mse_q3    | 9.14e-05 |
| samples   | 7.7e+05  |
| step      | 1.1e+05  |
| vb        | 0.000102 |
| vb_q0     | 0.000431 |
| vb_q1     | 8.59e-06 |
| vb_q2     | 2.31e-06 |
| vb_q3     | 1.2e-06  |
------------------------
------------------------
| grad_norm | 0.138    |
| loss      | 0.00354  |
| loss_q0   | 0.013    |
| loss_q1   | 0.00111  |
| loss_q2   | 0.000214 |
| loss_q3   | 0.000103 |
| mse       | 0.00331  |
| mse_q0    | 0.0121   |
| mse_q1    | 0.0011   |
| mse_q2    | 0.000212 |
| mse_q3    | 0.000102 |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 0.000229 |
| vb_q0     | 0.000929 |
| vb_q1     | 8.31e-06 |
| vb_q2     | 2.01e-06 |
| vb_q3     | 1.33e-06 |
------------------------
------------------------
| grad_norm | 0.16     |
| loss      | 0.00524  |
| loss_q0   | 0.0166   |
| loss_q1   | 0.000965 |
| loss_q2   | 0.000216 |
| loss_q3   | 0.000104 |
| mse       | 0.00471  |
| mse_q0    | 0.0149   |
| mse_q1    | 0.000958 |
| mse_q2    | 0.000214 |
| mse_q3    | 0.000103 |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 0.000524 |
| vb_q0     | 0.00174  |
| vb_q1     | 7.13e-06 |
| vb_q2     | 1.95e-06 |
| vb_q3     | 1.28e-06 |
------------------------
------------------------
| grad_norm | 0.174    |
| loss      | 0.0139   |
| loss_q0   | 0.063    |
| loss_q1   | 0.00105  |
| loss_q2   | 0.000314 |
| loss_q3   | 9.52e-05 |
| mse       | 0.00338  |
| mse_q0    | 0.0138   |
| mse_q1    | 0.00104  |
| mse_q2    | 0.000311 |
| mse_q3    | 9.4e-05  |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 0.0106   |
| vb_q0     | 0.0492   |
| vb_q1     | 7.74e-06 |
| vb_q2     | 2.74e-06 |
| vb_q3     | 1.2e-06  |
------------------------
------------------------
| grad_norm | 0.136    |
| loss      | 0.00323  |
| loss_q0   | 0.0149   |
| loss_q1   | 0.00118  |
| loss_q2   | 0.00023  |
| loss_q3   | 0.0001   |
| mse       | 0.00307  |
| mse_q0    | 0.014    |
| mse_q1    | 0.00117  |
| mse_q2    | 0.000228 |
| mse_q3    | 9.91e-05 |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 0.000162 |
| vb_q0     | 0.00085  |
| vb_q1     | 8.71e-06 |
| vb_q2     | 2.11e-06 |
| vb_q3     | 1.32e-06 |
------------------------
------------------------
| grad_norm | 0.0966   |
| loss      | 0.00271  |
| loss_q0   | 0.00802  |
| loss_q1   | 0.000985 |
| loss_q2   | 0.000245 |
| loss_q3   | 9.39e-05 |
| mse       | 0.00262  |
| mse_q0    | 0.00774  |
| mse_q1    | 0.000977 |
| mse_q2    | 0.000243 |
| mse_q3    | 9.27e-05 |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 8.7e-05  |
| vb_q0     | 0.000282 |
| vb_q1     | 7.24e-06 |
| vb_q2     | 2.2e-06  |
| vb_q3     | 1.19e-06 |
------------------------
------------------------
| grad_norm | 0.0806   |
| loss      | 0.00211  |
| loss_q0   | 0.00787  |
| loss_q1   | 0.000784 |
| loss_q2   | 0.000283 |
| loss_q3   | 9.79e-05 |
| mse       | 0.00205  |
| mse_q0    | 0.00759  |
| mse_q1    | 0.000778 |
| mse_q2    | 0.000281 |
| mse_q3    | 9.66e-05 |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 6.52e-05 |
| vb_q0     | 0.000274 |
| vb_q1     | 5.83e-06 |
| vb_q2     | 2.56e-06 |
| vb_q3     | 1.28e-06 |
------------------------
------------------------
| grad_norm | 0.0795   |
| loss      | 0.00263  |
| loss_q0   | 0.00885  |
| loss_q1   | 0.000785 |
| loss_q2   | 0.000232 |
| loss_q3   | 9.88e-05 |
| mse       | 0.00255  |
| mse_q0    | 0.00858  |
| mse_q1    | 0.000779 |
| mse_q2    | 0.00023  |
| mse_q3    | 9.76e-05 |
| samples   | 7.71e+05 |
| step      | 1.1e+05  |
| vb        | 7.46e-05 |
| vb_q0     | 0.000268 |
| vb_q1     | 5.77e-06 |
| vb_q2     | 2.08e-06 |
| vb_q3     | 1.23e-06 |
------------------------
